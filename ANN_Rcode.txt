Data Repository (http://archive.ics.uci.edu/ml)


#exploring and preparing the data
concrete <- read.csv("concrete.csv")
str(concrete)

normalize <- function(x) 
{
return((x - min(x)) / (max(x) - min(x)))
}
concrete_norm <- as.data.frame(lapply(concrete, normalize))
summary(concrete_norm$strength)

concrete_train <- concrete_norm[1:773, ]
concrete_test <- concrete_norm[774:1030, ]


#training a model on the data
concrete_model <- neuralnet(strength ~ cement + slag+ ash + water + superplastic + coarseagg + fineagg + age,data = concrete_train)
plot(concrete_model)


#evaluating model performance
model_results <- compute(concrete_model, concrete_test[1:8])
predicted_strength <- model_results$net.result
cor(predicted_strength, concrete_test$strength)


#improving model performance
concrete_model2 <- neuralnet(strength ~ cement + slag +
ash + water + superplastic +
coarseagg + fineagg + age,
data = concrete_train, hidden = 5)

plot(concrete_model2)

model_results2 <- compute(concrete_model2, concrete_test[1:8])
predicted_strength2 <- model_results2$net.result
cor(predicted_strength2, concrete_test$strength)